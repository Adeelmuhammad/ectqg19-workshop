---
title: 'R: Data structures'
author: "Roger Bivand"
date: "Thursday, 5 September 2019, 09:45-10:15"
output:
  pdf_document: default
  html_document: null
link-citations: yes
bibliography: rmd.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

### Required current contributed CRAN packages:

I am running R 3.6.1, with recent `update.packages()`.

```{r, echo=TRUE}
needed <- c("sf", "stars", "lwgeom")
```

## Vectors, matrices and `data.frames`

### Simple vectors

In R, scalars are vectors of unit length, so most data are vectors or combinations of vectors. The printed results are prepended by a curious `[1]`; all these results are unit length vectors. We can combine several objects with `c()`:

```{r vect1, echo = TRUE}
a <- c(2, 3)
a
sum(a)
str(a)
aa <- rep(a, 50)
aa
```

The single square brackets `[]` are used to access or set elements of vectors (the colon `:` gives an integer sequence); negative indices drop elements:

```{r vect2, echo = TRUE}
length(aa)
aa[1:10]
sum(aa)
sum(aa[1:10])
sum(aa[-(11:length(aa))])
```

### Arithmetic under the hood

Infix syntax is just a representation of the actual underlying forms

```{r vect2a, echo = TRUE}
a[1] + a[2]
sum(a)
`+`(a[1], a[2])
Reduce(`+`, a)
```

We've done arithmetic on scalars, we can do vector-scalar arithmetic:

```{r vect3, echo = TRUE}
sum(aa)
sum(aa+2)
sum(aa)+2
sum(aa*2)
sum(aa)*2
```

But vector-vector arithmetic poses the question of vector length and recycling (the shorter one gets recycled):


```{r vect4, echo = TRUE}
v5 <- 1:5
v2 <- c(5, 10)
v5 * v2
v2_stretch <- rep(v2, length.out=length(v5))
v2_stretch
v5 * v2_stretch
```

In working with real data, we often meet missing values, coded by NA meaning Not Available:

```{r NA, echo = TRUE}
anyNA(aa)
is.na(aa) <- 5
aa[1:10]
anyNA(aa)
sum(aa)
sum(aa, na.rm=TRUE)
```

### Checking data


One way to check our input data is to print in the console --- this works with small objects as we've seen, but for larger objects we need methods:


```{r check1, echo = TRUE}
big <- 1:(10^5)
length(big)
head(big)
str(big)
summary(big)
```

### Basic vector types

There are `length`, `head`, `str` (*str*ucture) and `summary` methods for many types of objects. `str` also gives us a hint of the type of object and its dimensions. We've seen a couple of uses of `str` so far, `str(a)` was `num` and `str(big)` was `int`, what does this signify? They are both numbers, but of different types.

There are six basic vector types: list, integer, double, logical, character and [complex](http://www.johnmyleswhite.com/notebook/2009/12/18/using-complex-numbers-in-r/). The derived type factor (to which we return shortly) is integer with extra information. `str` reports these as int, num, logi, chr and cplx, and lists are enumerated recursively. In RStudio you see more or less the `str` output in the environment pane as Values in the list view; the grid view adds the object size in memory. From early S, we have `typeof` and `storage.mode` (including single precision, not used in R) --- these are important for interfacing C, C++, Fortran and other languages. Beyond this is `class`, but then the different class systems (S3 and formal S4) complicate things. Objects such as vectors may also have attributes in which their class and other information may be placed. Typically, a lot of use is made of attributes to squirrel away strings and short vectors. 

`is` methods are used to test types of objects; note that integers are also seen as numeric:

```{r coerce1, echo = TRUE}
set.seed(1)
x <- runif(50, 1, 10)
is.numeric(x)
y <- rpois(50, lambda=6)
is.numeric(y)
is.integer(y)
xy <- x < y
is.logical(xy)
```

`as` methods try to convert between object types and are widely used:

```{r coerce2, echo = TRUE}
str(as.integer(xy))
str(as.numeric(y))
str(as.character(y))
str(as.integer(x))
```

### The data frame object

First, let us see that is behind the `data.frame` object: the `list` object. `list` objects are vectors that contain other objects, which can be addressed by name or by 1-based indices. Like the vectors we have already met, lists can be  accessed and manipulated using square brackets `[]`. Single list elements can be accessed and manipulated using double square brackets `[[]]`. 

### List objects

Starting with four vectors of differing types, we can assemble a list object; as we see, its structure is quite simple. The vectors in the list may vary in length, and lists can (and do often) include lists

```{r , echo = TRUE}
V1 <- 1:3
V2 <- letters[1:3]
V3 <- sqrt(V1)
V4 <- sqrt(as.complex(-V1))
L <- list(v1=V1, v2=V2, v3=V3, v4=V4)
str(L)
L$v3[2]
L[[3]][2]
```

### Data Frames

Our `list` object contains four vectors of different types but of the same length; conversion to a `data.frame` is convenient. Note that by default strings are converted into factors:

```{r , echo = TRUE}
DF <- as.data.frame(L)
str(DF)
DF <- as.data.frame(L, stringsAsFactors=FALSE)
str(DF)
```

We can also provoke an error in conversion from a valid `list` made up of vectors of different length to a `data.frame`:


```{r , echo = TRUE}
V2a <- letters[1:4]
V4a <- factor(V2a)
La <- list(v1=V1, v2=V2a, v3=V3, v4=V4a)
DFa <- try(as.data.frame(La, stringsAsFactors=FALSE), silent=TRUE)
message(DFa)
```

We can access `data.frame` elements as `list` elements, where the `$` is effectively the same as `[[]]` with the list component name as a string:

```{r , echo = TRUE}
DF$v3[2]
DF[[3]][2]
DF[["v3"]][2]
```

Since a `data.frame` is a rectangular object with named columns with equal numbers of rows, it can also be indexed like a matrix, where the rows are the first index and the columns (variables) the second:


```{r , echo = TRUE}
DF[2, 3]
DF[2, "v3"]
str(DF[2, 3])
str(DF[2, 3, drop=FALSE])
```

If we coerce a `data.frame` containing a character vector or factor into a matrix, we get a character matrix; if we extract an integer and a numeric column, we get a numeric matrix.

```{r , echo = TRUE}
as.matrix(DF)
as.matrix(DF[,c(1,3)])
```

The fact that `data.frame` objects descend from `list` objects is shown by looking at their lengths; the length of a matrix is not its number of columns, but its element count:

```{r , echo = TRUE}
length(L)
length(DF)
length(as.matrix(DF))
```

There are `dim` methods for `data.frame` objects and matrices (and arrays with more than two dimensions); matrices and arrays are seen as vectors with dimensions; `list` objects have no dimensions:


```{r , echo = TRUE}
dim(L)
dim(DF)
dim(as.matrix(DF))
```

```{r , echo = TRUE}
str(as.matrix(DF))
```

`data.frame` objects have `names` and `row.names`, matrices have `dimnames`, `colnames` and `rownames`; all can be used for setting new values:

```{r , echo = TRUE}
row.names(DF)
names(DF)
names(DF) <- LETTERS[1:4]
names(DF)
str(dimnames(as.matrix(DF)))
```

R objects have attributes that are not normally displayed, but which show their structure and class (if any); we can see that `data.frame` objects are quite different internally from matrices:


```{r , echo = TRUE}
str(attributes(DF))
str(attributes(as.matrix(DF)))
```

If the reason for different vector lengths was that one or more observations are missing on that variable, `NA` should be used; the lengths are then equal, and a rectangular table can be created:

```{r , echo = TRUE}
V1a <- c(V1, NA)
V3a <- sqrt(V1a)
La <- list(v1=V1a, v2=V2a, v3=V3a, v4=V4a)
DFa <- as.data.frame(La, stringsAsFactors=FALSE)
str(DFa)
```


## New style spatial vector representation

### The **sf** package

The recent **sf** package bundles GDAL and GEOS (**sp** just defined the classes and methods, leaving I/O and computational geometry to other packages **rgdal** and **rgeos**). **sf** uses `data.frame` objects with one (or more) geometry column for vector data. The representation follows ISO 19125 (*Simple Features*), and has WKT (text) and WKB (binary) representations (used by GDAL and GEOS internally). The drivers include PostGIS and other database constructions permitting selection, and WFS for server APIs. These are the key references for **sf**: [@geocompr], [@sdsr], [@RJ-2018-009], package [vignettes](https://cran.r-project.org/package=sf) and blog posts on (https://www.r-spatial.org/).


```{r, echo=TRUE}
library(sf)
```

The `st_read()` method, here for a `"character"` first object giving the file name and path, uses GDAL through **Rcpp** to identify the driver required, and to use it to read the feature geometries and fields. The character string fields are not converted to `"factor"` representation, as they are not categorical variables:

```{r, echo=TRUE}
lux <- st_read("../data/lux_regions.gpkg", stringsAsFactors=FALSE)
```

The vector drivers available to me with my GDAL build are:

```{r, echo=TRUE}
st_drivers(what="vector")[,c(2:4, 7)]
```

Package **sf** provides handling of feature data, where feature
geometries are points, lines, polygons or combinations of those.
It implements the full set of geometric functions described in the
_simple feature access_ standard, and some. The basic storage is
very simple, and uses only base R types (list, matrix).

* feature sets are held as records (rows) in `"sf"` objects, inheriting from `"data.frame"`
* `"sf"` objects have at least one simple feature geometry list-column of class `"sfc"`
* geometry list-columns are *sticky*, that is they stay stuck to the object when subsetting columns, for example using `[`
* `"sfc"` geometry list-columns have a bounding box and a coordinate reference system as attribute, and a class attribute pointing out the common type (or `"GEOMETRY"` in case of a mix)
* a single simple feature geometry is of class `"sfg"`, and further classes pointing out dimension and type

Storage of simple feature geometry:

* `"POINT"` is a numeric vector
* `"LINESTRING"` and `"MULTIPOINT"` are numeric matrix, points/vertices in rows
* `"POLYGON"` and `"MULTILINESTRING"` are lists of matrices
* `"MULTIPOLYGON"` is a lists of those
* `"GEOMETRYCOLLECTION"` is a list of typed geometries


```{r, echo=TRUE}
class(lux)
```

The columns of the `"data.frame"` object have these names:

```{r, echo=TRUE}
names(lux)
```

Two of the attributes of the object are those all `"data.frame"` objects possess: `names` shown above and `row.names`. The fourth, `sf_column` gives the name of the active geometry column.

```{r, echo=TRUE}
names(attributes(lux))
```

The `$` access operator lets us operate on a single column of the object as with any other `"data.frame"` object:

```{r, echo=TRUE}
hist(lux$ghsl_pop)
```

Using the attribute value to extract the name of the geometry column, and the `[[` access operator to give programmatic access to a column by name, we can see that the `"sfc"` object is composed of `POLYGON` objects:

```{r, echo=TRUE}
class(lux[[attr(lux, "sf_column")]])
```

The geometry column is a list column, of the same length as the other columns in the `"data.frame"` object.

```{r, echo=TRUE}
is.list(lux[[attr(lux, "sf_column")]])
```

`"sf"` objects may be subsetted by row and column in the same way as regular `"data.frame"` objects, with the implicit understanding that the geometry column is _sticky_; here we choose only the first column, but the geometry column follows along, _stuck_ to the subsetted object, and obviously subsetted by row too.


```{r, echo=TRUE}
class(lux[1:5, 1])
```

Geometry columns have their own list of attributes, the count of empty geometries, the coordinate reference system, the precision and the bounding box (subsetting will refresh the bounding box; transformation will update the coordinate reference system and the bounding box):

```{r, echo=TRUE}
attributes(lux[[attr(lux, "sf_column")]])
```
The coordinate reference system is an object of class `"crs"`:

```{r, echo=TRUE}
class(attr(lux[[attr(lux, "sf_column")]], "crs"))
```

It contains an integer EPSG code (so far not compound codes), and a PROJ string:

```{r, echo=TRUE}
str(attr(lux[[attr(lux, "sf_column")]], "crs"))
```

Objects of this class can be instantiated for example by giving the relevant EPSG code:

```{r, echo=TRUE}
st_crs(4674)
```

```{r, echo=TRUE}
st_crs(31983)
```

We can drill down to the first feature geometry `"sfg"` object, which is a matrix with a class attribute - a vector of three elements, `"XY"` for two dimensions, `"POLYGON"` for the simple features definition, and `"sfg"` as the container class:

```{r, echo=TRUE}
str(lux[[attr(lux, "sf_column")]][[1]])
```

### Checking the data

Stepping back, we can try to check where the `POPULATION` field/column came from; the Luxembourg public data source provides a file, here as `"geojson"` https://data.public.lu/en/datasets/population-per-municipality/:

```{r, echo=TRUE}
pop <- st_read("../data/statec_population_by_municipality.geojson")
```

The difference is in the ordering of the features in the two objects:

```{r, echo=TRUE}
all.equal(pop$POPULATION, lux$POPULATION)
o <- match(as.character(pop$LAU2), as.character(lux$LAU2))
all.equal(pop$POPULATION, lux$POPULATION[o])
```

We'll also be able to look at the differences between population counts from this data source and from GHSL https://ghsl.jrc.ec.europa.eu/; the data source is probably the 2011 census:

```{r, echo=TRUE}
plot(lux[, c("POPULATION", "ghsl_pop")])
```

The trees are from https://data.public.lu/en/datasets/remarkable-trees/, but in projected, not geographical coordinates:

```{r, echo=TRUE}
trees <- st_read("../data/trees/anf_remarkable_trees_0.shp")
```

If we would like to find the areas of the administrative units, we could use spherical areas from **lwgeom**, or take them by transforming to for example the projection of the trees:

```{r, echo=TRUE}
area_sph <- lwgeom::st_geod_area(lux)
lux_tmerc <- st_transform(lux, 2169)
area_tmerc <- st_area(lux_tmerc)
```

There are small differences between these area outputs:

```{r, echo=TRUE}
lux_tmerc$area <- area_tmerc
lux_tmerc$area_err <- (lux_tmerc$area - area_sph)/lux_tmerc$area
summary(lux_tmerc$area_err)
```


```{r, echo=TRUE}
plot(lux_tmerc[, "area_err"], axes=TRUE, main="area difference in m2 per m2")
```

The area is in square meters, so we can use facilities in **units** to change to square kilometers to calculate population densities:

```{r, echo=TRUE}
units(lux_tmerc$area)
```

```{r, echo=TRUE}
units(lux_tmerc$area) <- "km^2"
units(lux_tmerc$area)
```

```{r, echo=TRUE}
lux_tmerc$pop_den <- lux_tmerc$POPULATION/lux_tmerc$area
summary(lux_tmerc$pop_den)
```

```{r, echo=TRUE}
lux_tmerc$ghsl_den <- lux_tmerc$ghsl_pop/lux_tmerc$area
summary(lux_tmerc$ghsl_den)
```

We can do the same kinds of sourcing checks with the tree counts:

```{r, echo=TRUE}
trees_sgbp <- st_intersects(lux_tmerc, trees)
trees_cnt <- sapply(trees_sgbp, length)
all.equal(trees_cnt, lux_tmerc$tree_count)
```

But we are not ready to move on yet.

### PROJ

Because so much open source (and other) software uses the PROJ library and framework, many are affected when PROJ upgrades. Until very recently, PROJ has been seen as very reliable, and the changes taking place now are intended to confirm and reinforce this reliability. Before PROJ 5 (PROJ 6 is out now, PROJ 7 is coming early in 2020), the `+datum=` tag was used, perhaps with `+towgs84=` with three or seven coefficients, and possibly `+nadgrids=` where datum transformation grids were available. However, transformations from one projection to another first inversed to longitude-latitude in WGS84, then projected on to the target projection.


### Big bump coming:

'Fast-forward 35 years and PROJ.4 is everywhere: It provides coordinate handling for almost every geospatial program, open or closed source. Today,  we  see  a  drastical  increase  in  the  need  for  high  accuracy  GNSS  coordinate  handling, especially in the agricultural and construction engineering sectors.  This need for geodetic-accuracy transformations  is  not  satisfied  by  "classic  PROJ.4".  But  with  the  ubiquity  of  PROJ.4,  we  can provide these transformations "everywhere", just by implementing them as part of PROJ.4' [@evers+knudsen17].


### Escaping the WGS84 hub/pivot: PROJ and OGC WKT2


Following the introduction of geodetic modules and pipelines in PROJ 5 [@knudsen+evers17; @evers+knudsen17], PROJ 6 moves further. Changes in the legacy PROJ representation and WGS84 transformation hub have been coordinated through the [GDAL barn raising](https://gdalbarn.com/) initiative. Crucially WGS84 often ceases to be the pivot for moving between datums. A new OGC WKT is coming, and an SQLite EPSG file database has replaced CSV files. SRS will begin to support 3D by default, adding time too as SRS change. See also [PROJ migration notes](https://proj.org/development/migration.html).

There are very useful postings on the PROJ mailing list from Martin Desruisseaux, first [proposing clarifications](https://lists.osgeo.org/pipermail/proj/2019-July/008748.html) and a [follow-up](https://lists.osgeo.org/pipermail/proj/2019-August/008750.html) including a summary:

> * "Early binding": hub transformation technique.

> * "Late binding": hub transformation technique NOT used, replaced by
a more complex technique consisting in searching parameters in the
EPSG database after the transformation context (source, target,
epoch, area of interest) is known.

> * The problem of hub transformation technique is independent of WGS84.
It is caused by the fact that transformations to/from the hub are
approximate. Any other hub we could invent in replacement of WGS84
will have the same problem, unless we can invent a hub for which
transformations are exact (I think that if such hub existed, we
would have already heard about it).

> The solution proposed by ISO 19111 (in my understanding) is:

> * Forget about hub (WGS84 or other), unless the simplicity of
early-binding is considered more important than accuracy.

> * Associating a CRS to a coordinate set (geometry or raster) is no
longer sufficient. A {CRS, epoch} tuple must be associated. ISO
19111 calls this tuple "Coordinate metadata". From a programmatic
API point of view, this means that getCoordinateReferenceSystem()
method in Geometry objects (for instance) needs to be replaced by a
getCoordinateMetadata() method.

Maybe watch Even Roualt's recent FOSS4G talk: https://media.ccc.de/v/bucharest-198-revamp-of-coordinate-reference-system-management-in-the-osgeo-c-c-stack-with-proj-and-gdal

The `projinfo` utility is available with the external PROJ library, so most likely not in general; this is for PROJ 6.1.1 (current as of writing):

```{r, echo=TRUE}
cat(system("projinfo EPSG:4326 -o PROJ", intern=TRUE), sep="\n")
```



```{r, echo=TRUE}
cat(system("projinfo EPSG:4326 -o WKT1_GDAL", intern=TRUE), sep="\n")
```



```{r, echo=TRUE}
cat(system("projinfo EPSG:4326 -o WKT2_2018", intern=TRUE), sep="\n")
```



```{r, echo=TRUE}
cat(system("projinfo EPSG:2169 -o PROJ", intern=TRUE), sep="\n")
```




```{r, echo=TRUE}
cat(system("projinfo EPSG:2169 -o WKT1_GDAL", intern=TRUE), sep="\n")
```



```{r, echo=TRUE}
cat(system("projinfo EPSG:2169 -o WKT2_2018", intern=TRUE), sep="\n")
```



```{r, echo=TRUE}
cat(system("projinfo -s EPSG:4326 -t EPSG:2169 -o PROJ", intern=TRUE), sep="\n")
```

### Raster

The GHSL data from https://ghsl.jrc.ec.europa.eu/ and provided in the `ghsl_pop` column is not documented here (yet). Using the GeoTIFF file (which turns out to be `+proj=moll`), we can read using a GDAL driver, first into memory, then proxy:

```{r, echo=TRUE}
library(stars)
system.time(ghsl0 <- read_stars("../data/ghsl.tiff", proxy=FALSE))
ghsl0
```



```{r, echo=TRUE}
system.time(ghsl1 <- read_stars("../data/ghsl.tiff", proxy=TRUE))
ghsl1
```

```{r, echo=TRUE}
plot(ghsl0)
```

Using the aggregate method on the input raster in memory warped to the Luxembourg transverse Mercator projection, by the municipality boundaries in `lux_tmerc`, we can recover the population counts. 

```{r, echo=TRUE}
system.time(ghsl_sum0 <- aggregate(st_warp(ghsl0, crs=2169, cellsize=250, use_gdal=FALSE), lux_tmerc, sum))
```

Using the proxy in this case takes about the same time:

```{r, echo=TRUE}
system.time(ghsl_sum1 <- aggregate(st_warp(ghsl1, crs=2169, cellsize=250, use_gdal=FALSE), lux_tmerc, sum))
```

```{r, echo=TRUE}
system.time(ghsl_sum2 <- aggregate(ghsl0, st_transform(lux, crs=st_crs(ghsl0)$proj4string), sum))
```

The output values following warping are closely aligned with, but differ a little from those included in the vector object read to begin with; it looks as though the vector object was transformed to match the raster before aggregation:

```{r, echo=TRUE}
summary(cbind(orig=lux_tmerc$ghsl_pop, warp=ghsl_sum0$ghsl.tiff, warp_proxy=ghsl_sum1$ghsl.tiff, moll=ghsl_sum2$ghsl.tiff))
```

```{r, echo=TRUE}
lux_tmerc$ghsl_tiff <- ghsl_sum0$ghsl.tiff
lux_tmerc$ghsl_warp_diff <- lux_tmerc$ghsl_tiff - lux_tmerc$ghsl_pop
plot(lux_tmerc[,"ghsl_warp_diff"])
```

```{r, echo=TRUE}
st_write(lux_tmerc, "../data/lux_tmerc.gpkg", delete_dsn=TRUE)
```
